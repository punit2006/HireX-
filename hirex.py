# -*- coding: utf-8 -*-
"""HireX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12_S3D5CH6cBSphN746thNs5yPzK2dkq8
"""

!pip install -q streamlit pyngrok requests python-dotenv

import os

# üîê Replace this with your actual Groq API Key
api_key = "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"

# Set in env for testing in notebook
os.environ["APII"] = api_key

# Save to .env for Streamlit subprocess
with open(".env", "w") as f:
    f.write(f"APII={api_key}")

from IPython.display import display, HTML

# Set global font and styling for Colab output
display(HTML("""
<style>
    html, body {
        font-family: 'Segoe UI', sans-serif;
        font-size: 16px;
    }
    .question-block {
        background-color: #f9f9f9;
        padding: 12px;
        border-left: 5px solid #4CAF50;
        margin-bottom: 16px;
        border-radius: 6px;
    }
</style>
"""))

with open("prompts.py", "w") as f:
  f.write('''def get_intro_prompt():
    return """üëã Welcome to **HireX** ‚Äì your smart AI Hiring Assistant!
We're here to generate technical interview questions tailored to your skills and experience.
Let‚Äôs get started with a few quick details."""

ef get_intro_prompt():
    return """üëã Welcome to **HireX** ‚Äì your smart AI Hiring Assistant!
We're here to generate technical interview questions tailored to your skills and experience.
Let‚Äôs get started with a few quick details."""

def get_info_prompt():
    return """
Please fill out the following details to help us customize your interview questions:
1. Full Name
2. Email
3. Phone Number
4. Years of Experience
5. Desired Position(s)
6. Current Location
7. Your Tech Stack (comma-separated)
"""

def generate_question_only_prompt(tech_stack, experience):
    return f"""
Generate 5 **technical coding interview questions only** (no answers) for someone with {experience} years of experience in the following tech stack:

{tech_stack}

The questions should test coding ability ‚Äî logic, implementation, algorithms, or systems ‚Äî using the mentioned technologies.

Respond only in this format:
1. **Question:** ...
2. **Question:** ...
3. **Question:** ...
4. **Question:** ...
5. **Question:** ...
"""

def generate_solution_only_prompt(tech_stack, experience, questions):
    return f"""
You are an AI coding interview assistant.

Generate answers to the following 5 coding interview questions for someone with {experience} years of experience in:

Tech Stack: {tech_stack}

Each answer must include:
- ‚úÖ Complete, executable code in the tech stack mentioned
- ‚úÖ Brief explanation of what the code does and why

Questions:
{questions}

Format:
1. **Answer:**
```{tech_stack.lower()}
# your code here

Respond in this format:
1. **Answer:** ...
2. **Answer:** ...
3. **Answer:** ...
4. **Answer:** ...
5. **Answer:** ...
"""

def generate_thinking_prompt(tech_stack, experience):
    return f"""
Generate 5 advanced or creative "thinking" (open-ended, discussion) interview questions for someone with {experience} years of experience in {tech_stack}.
Number and return questions only, without answers.
"""''')

# Write app.py
with open("app.py", "w") as f:
    f.write("""
import streamlit as st
import os
import requests
from dotenv import load_dotenv
from prompts import get_intro_prompt, get_info_prompt, generate_question_only_prompt, generate_solution_only_prompt, generate_thinking_prompt

load_dotenv()
st.set_page_config(page_title='HireX AI Assistant', layout='centered')
st.title('üë©‚Äçüíº HireX: Smart Hiring Assistant')

def query_llm(prompt):
    api_key = os.getenv('APII')
    headers = {'Authorization': f'Bearer ' + api_key, 'Content-Type': 'application/json'}
    payload = {
        'model': 'llama3-8b-8192',
        'messages': [{'role': 'user', 'content': prompt}],
        'temperature': 0.7
    }

    try:
        response = requests.post('https://api.groq.com/openai/v1/chat/completions', headers=headers, json=payload)
        result = response.json()
        return result['choices'][0]['message']['content']
    except Exception as e:
        st.error("‚ö†Ô∏è Failed to get a valid response from the LLM.")
        st.write("Error details:", str(e))
        if 'result' in locals():
            st.write("Raw response:", result)
        return "‚ö†Ô∏è Error: Unable to generate a response. Please check your API key or prompt."

if 'step' not in st.session_state: st.session_state.step = 0
if 'info' not in st.session_state: st.session_state.info = {}
if 'questions' not in st.session_state: st.session_state.questions = ''
if 'solutions' not in st.session_state: st.session_state.solutions = ''
if 'thinking_questions' not in st.session_state: st.session_state.thinking_questions = ''
if 'show_solutions' not in st.session_state: st.session_state.show_solutions = False
if 'show_thinking' not in st.session_state: st.session_state.show_thinking = False

# Step 0
if st.session_state.step == 0:
    st.write(get_intro_prompt())
    if st.button('Start'): st.session_state.step = 1

# Step 1
elif st.session_state.step == 1:
    st.write(get_info_prompt())
    with st.form('info_form'):
        name = st.text_input('Full Name')
        email = st.text_input('Email')
        phone = st.text_input('Phone Number')
        experience = st.text_input('Years of Experience')
        position = st.text_input('Desired Position(s)')
        location = st.text_input('Current Location')
        tech_stack = st.text_area('Your Tech Stack')
        submitted = st.form_submit_button('Submit')
    if submitted and all([name, email, phone, experience, tech_stack]):
        st.session_state.info = {
            'name': name, 'email': email, 'phone': phone,
            'experience': experience, 'tech_stack': tech_stack
        }
        question_prompt = generate_question_only_prompt(tech_stack, experience)
        st.session_state.questions = query_llm(question_prompt)
        st.session_state.solutions = ''
        st.session_state.step = 2

# Step 2
elif st.session_state.step == 2:
    st.subheader('üìù 5 Coding Interview Questions')
    st.write(st.session_state.questions)

    if not st.session_state.show_solutions:
        if st.button('üîç Show Solutions'):
            solution_prompt = generate_solution_only_prompt(
                st.session_state.info['tech_stack'],
                st.session_state.info['experience'],
                st.session_state.questions
            )
            st.session_state.solutions = query_llm(solution_prompt)
            st.session_state.show_solutions = True
            st.rerun()

    if st.session_state.show_solutions:
        st.subheader('‚úÖ Solutions to the 5 Questions:')
        st.write(st.session_state.solutions)

        if not st.session_state.show_thinking:
            if st.button('üí° Try Thinking Questions'):
                thinking_prompt = generate_thinking_prompt(
                    st.session_state.info['tech_stack'],
                    st.session_state.info['experience']
                )
                st.session_state.thinking_questions = query_llm(thinking_prompt)
                st.session_state.show_thinking = True
                st.rerun()

    if st.session_state.show_thinking:
        st.subheader('üí≠ Additional 5 Thinking Questions:')
        st.write(st.session_state.thinking_questions)

    if st.button('‚úÖ End Conversation'):
        st.session_state.step = 3
        st.rerun()

# Step 3
elif st.session_state.step == 3:
    st.success('üéâ Thank you for using HireX!')
""")

!pkill ngrok  # Kill any previous ngrok instances

from pyngrok import ngrok

# üîê Replace with your ngrok auth token if needed
ngrok.set_auth_token("305YkoBuFAvqGJ0J79jfc2tFHax_6zsdzunjnDm9zyUo3pdQK")

!streamlit run app.py &>/content/log.txt &  # Start in background

# Get public URL
public_url = ngrok.connect(addr=8501)
print("‚úÖ Your chatbot is live at:", public_url)

